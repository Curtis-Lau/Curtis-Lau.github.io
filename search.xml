<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>个人简介</title>
    <url>/post/35221811/</url>
    <content><![CDATA[<p>个人信息介绍，欢迎联系~</p>
<span id="more"></span>
<h3 id="个人信息"><a href="#个人信息" class="headerlink" title="个人信息"></a>个人信息</h3><ul>
<li>姓名：刘义来</li>
<li>性别：男</li>
<li>出生年月：1997 年02月</li>
<li>现居地址：浙江杭州</li>
<li>微信号：Curtis_L(添加记得备注哦~)</li>
</ul>
<h3 id="教育经历"><a href="#教育经历" class="headerlink" title="教育经历"></a>教育经历</h3><ul>
<li><p>硕士，浙江工商大学，金融学专业，2019.09~至今.</p>
</li>
<li><p>学士，盐城师范学院，经济学专业，2015.09~2019.06.</p>
</li>
<li><p>学士，盐城师范学院，财务会计与审计，2016.09~2019.06</p>
</li>
<li><p>期间技能证书：基金从业资格证、证券从业资格证、会计从业资格证</p>
<p>​                           CET6、CET4、计算机二级</p>
</li>
</ul>
<h3 id="校外实习"><a href="#校外实习" class="headerlink" title="校外实习"></a>校外实习</h3><ul>
<li><strong>江苏金湖农村商业银行金北支行，大堂经理助手，2017.07~2017.08</strong><ul>
<li><strong>工作描述：</strong>自学银行的各项工作以及各项理财产品、担保贷款业务、银行卡开卡等业务；协助大堂经理分流引导客户、为客户介绍理财产品等。</li>
</ul>
</li>
<li><strong>徐州三十七度教育咨询有限公司，专业课指导老师，2019.06~2019.09</strong><ul>
<li><strong>工作描述：</strong>专业课考试科目剖析、基础考点分析、相关知识点讲解；考试大纲解析、真题解析以及重难点解析；全真模拟试卷测评讲解以及相关内部信息通报考前注意事项的告知。</li>
</ul>
</li>
</ul>
<h3 id="个人项目"><a href="#个人项目" class="headerlink" title="个人项目"></a>个人项目</h3><ul>
<li><strong>项目一</strong>：Contextual Bandit on Portfolio Management Based on GA<ul>
<li>介绍：基于HS300股票池，运用推荐算法进行投资组合的选取，这里推荐算法用的是上下文相关的Bandit算法里的LinUCB算法，再结合遗传算法（GA）优化LinUCB参数，目的是模拟一个推荐系统，根据投资者的偏好推荐投资组合。</li>
<li>详见：<a href="https://github.com/Curtis-Lau/LinUCB-Based-on-GA">https://github.com/Curtis-Lau/LinUCB-Based-on-GA</a></li>
</ul>
</li>
<li><strong>项目二</strong>：Contextual Bandit on Portfolio Management Based on Decision Tree<ul>
<li>介绍：基于HS300股票池，用决策树根据相关因子将股票分类，根据分类运用LinUCB算法推荐投资组合。</li>
<li>详见：<a href="https://github.com/Curtis-Lau/LinUCB-Based-on-Decision-Tree">https://github.com/Curtis-Lau/LinUCB-Based-on-Decision-Tree</a></li>
</ul>
</li>
<li><strong>项目二</strong>：慧博研投(<a href="http://www.hibor.com.cn/)研报数据的网络爬虫">http://www.hibor.com.cn/)研报数据的网络爬虫</a><ul>
<li>介绍：主要是爬取慧博研投网址投资研报板块的网址、标题、摘要。</li>
<li>详见：<a href="https://github.com/Curtis-Lau/crawl-hibor">https://github.com/Curtis-Lau/crawl-hibor</a></li>
</ul>
</li>
<li><p><strong>项目三</strong>：2020年十七届中国研究生数学建模竞赛B题</p>
<ul>
<li>介绍：该题目是“汽油辛烷值优化建模”，题1是数据处理，题2是筛选变量，题3是建立预测模型，题4是主要变量的优化方案，题5是模型的可视化。</li>
<li>详见：<a href="https://github.com/Curtis-Lau/2020GMCM">https://github.com/Curtis-Lau/2020GMCM</a></li>
</ul>
<h3 id="职场技能"><a href="#职场技能" class="headerlink" title="职场技能"></a>职场技能</h3></li>
<li><p>熟悉</p>
<ul>
<li>Python/R：机器学习、强化学习、数据挖掘、大数据处理、网络爬虫</li>
<li>Office</li>
</ul>
</li>
<li><p>了解</p>
<ul>
<li>matlab</li>
<li>深度学习</li>
</ul>
</li>
</ul>
<h3 id="获奖情况"><a href="#获奖情况" class="headerlink" title="获奖情况"></a>获奖情况</h3><ul>
<li>2020年“华为杯”第十七届中国研究生数学建模竞赛二等奖</li>
</ul>
<h3 id="自我评价"><a href="#自我评价" class="headerlink" title="自我评价"></a>自我评价</h3><ul>
<li>本人能够熟练运用Python、R、Office等软件进行数据挖掘、大数据分析、网络爬虫，同时也熟悉MongoDB数据库，对算法有一定的研究，2020年参加中国研究生数学建模竞赛并荣获二等奖，主要负责代码编写和提供算法思想。</li>
<li>在专业知识方面，能够熟练运用所学知识对国内外金融市场做一定的分析和预测，对我国金融市场的发展及现状有较好的理解。</li>
<li>善于沟通，具备活动策划和组织协调能力。良好的心态和责任感，吃苦耐劳，擅于管理时间，勇于面对变化和挑战。良好的学习能力，习惯制定切实可行的学习计划，勤于学习能不断提高。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>2020年研究生数学建模B题</title>
    <url>/post/aff86645/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>推荐算法：LinUCB</title>
    <url>/post/2973/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>算法</category>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>慧博研投爬虫</title>
    <url>/post/55099ab/</url>
    <content><![CDATA[<p>本文爬取的是慧博研投(www.hibor.com.cn)研报栏目的数据，主要包含研报的发布时间、标题、摘要的信息，然后将数据存于本地MongoDB数据库中。</p>
<span id="more"></span>
<h2 id="第一部分：导入需要的库"><a href="#第一部分：导入需要的库" class="headerlink" title="第一部分：导入需要的库"></a>第一部分：导入需要的库</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> schedule</span><br></pre></td></tr></table></figure>
<h2 id="第二部分：设置MongoDB"><a href="#第二部分：设置MongoDB" class="headerlink" title="第二部分：设置MongoDB"></a>第二部分：设置MongoDB</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">client = pymongo.MongoClient(host=<span class="string">&#x27;localhost&#x27;</span>,port=<span class="number">27017</span>)</span><br><span class="line">db = client[<span class="string">&#x27;hibor_report&#x27;</span>]</span><br><span class="line">collection_report = db[<span class="string">&quot;report_data&quot;</span>]</span><br><span class="line">report = &#123;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="第三部分：编写函数"><a href="#第三部分：编写函数" class="headerlink" title="第三部分：编写函数"></a>第三部分：编写函数</h2><h3 id="获取研报时间、标题以及具体网址"><a href="#获取研报时间、标题以及具体网址" class="headerlink" title="获取研报时间、标题以及具体网址"></a>获取研报时间、标题以及具体网址</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spider_detail_urls</span>(<span class="params">url</span>):</span></span><br><span class="line">    title_list = []</span><br><span class="line">    detail_url_list = []</span><br><span class="line">    <span class="built_in">id</span> = []</span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 UBrowser/6.2.4098.3 Safari/537.36&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.hibor.com.cn&#x27;</span>&#125;</span><br><span class="line">    response = requests.get(url, headers=headers)</span><br><span class="line">    text = response.content.decode()</span><br><span class="line">    bs = BeautifulSoup(text,<span class="string">&quot;html5lib&quot;</span>)</span><br><span class="line">    div = bs.find(<span class="string">&quot;div&quot;</span>,class_=<span class="string">&quot;leftn2&quot;</span>)</span><br><span class="line">    table = div.find(<span class="string">&quot;table&quot;</span>,class_=<span class="string">&quot;tab_ltnew&quot;</span>)</span><br><span class="line">    trs = table.find_all(<span class="string">&quot;tr&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> tr <span class="keyword">in</span> trs[::<span class="number">4</span>]:</span><br><span class="line">        span = tr.find(<span class="string">&quot;span&quot;</span>,class_=<span class="string">&quot;tab_lta&quot;</span>)</span><br><span class="line">        title =  <span class="built_in">list</span>(span.stripped_strings)[<span class="number">0</span>]</span><br><span class="line">        title_list.append(title)</span><br><span class="line">        _url = span.find(<span class="string">&quot;a&quot;</span>).get(<span class="string">&quot;href&quot;</span>)</span><br><span class="line">        detail_url = <span class="string">&quot;http://www.hibor.com.cn&quot;</span>+_url</span><br><span class="line">        detail_url_list.append(detail_url)</span><br><span class="line">        _<span class="built_in">id</span> = _url.split(<span class="string">&quot;_&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">id</span>.append(_<span class="built_in">id</span>)</span><br><span class="line">    report[<span class="string">&quot;id&quot;</span>] = <span class="built_in">id</span></span><br><span class="line">    report[<span class="string">&quot;连接&quot;</span>] = detail_url_list</span><br><span class="line">    report[<span class="string">&quot;标题&quot;</span>] = title_list</span><br><span class="line">    <span class="keyword">return</span> detail_url_list</span><br></pre></td></tr></table></figure>
<h3 id="根据具体网址获取研报摘要"><a href="#根据具体网址获取研报摘要" class="headerlink" title="根据具体网址获取研报摘要"></a>根据具体网址获取研报摘要</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spider_abstract</span>(<span class="params">detail_url_list</span>):</span></span><br><span class="line">    abstract = []</span><br><span class="line">    headers = &#123;<span class="string">&#x27;Accept-Language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;c=; safedog-flow-item=E452688EA9408CDB488598E819CA5CAE; UM_distinctid=17221e00e0a26-02018c653952da-d373666-144000-17221e00e0b56; did=67A671BFE; ASPSESSIONIDCABDDAQR=CNAHPHPCOHJBHKGHKGAGLOND; Hm_lvt_d554f0f6d738d9e505c72769d450253d=1589706231,1590147502,1590713899,1592128454; ASPSESSIONIDAQSSSRDS=KKGBDNADKNMBKOAAJFLPBJED; CNZZDATA1752123=cnzz_eid%3D1486449273-1589705206-https%253A%252F%252Fwww.baidu.com%252F%26ntime%3D1592138092; robih=OWvVuXvWjVoWKY9WdWsU; MBpermission=0; MBname=Curtis%5FLau; Hm_lpvt_d554f0f6d738d9e505c72769d450253d=1592140743&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;www.hibor.com.cn&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;http://www.hibor.com.cn/docdetail_2937262.html&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;X-Requested-With&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> detail_url_list:</span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        text = response.content.decode(<span class="string">&quot;gbk&quot;</span>)</span><br><span class="line">        bs = BeautifulSoup(text, <span class="string">&quot;html5lib&quot;</span>)</span><br><span class="line">        div = bs.find(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;neir&quot;</span>)</span><br><span class="line">        span = div.find(<span class="string">&quot;span&quot;</span>)</span><br><span class="line">        txt = <span class="built_in">list</span>(span.stripped_strings)</span><br><span class="line">        sentence = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> txt:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;http://www.hibor.com.cn&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> i:</span><br><span class="line">                sentence += i</span><br><span class="line">        abstract.append(sentence)</span><br><span class="line">    report[<span class="string">&quot;摘要&quot;</span>] = abstract</span><br><span class="line">    report_data = pd.DataFrame(report)</span><br><span class="line">    <span class="keyword">return</span> report_data</span><br></pre></td></tr></table></figure>
<h3 id="将数据导入MongoDB"><a href="#将数据导入MongoDB" class="headerlink" title="将数据导入MongoDB"></a>将数据导入MongoDB</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_mongodb</span>(<span class="params">report_data</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pd.DataFrame(collection_report.find()))==<span class="number">0</span>:</span><br><span class="line">        new_l = report_data.sort_values(by=<span class="string">&#x27;id&#x27;</span>, ascending=<span class="literal">True</span>)</span><br><span class="line">        collection_report.insert_many(json.loads(new_l.T.to_json()).values())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        last_id = pd.DataFrame(collection_report.find()).sort_values(by=<span class="string">&quot;id&quot;</span>, ascending=<span class="literal">False</span>)[<span class="string">&quot;id&quot;</span>].<span class="built_in">max</span>()</span><br><span class="line">        in_list = report_data[report_data[<span class="string">&#x27;id&#x27;</span>] &gt; last_id]</span><br><span class="line">        new_l = in_list.sort_values(by=<span class="string">&#x27;id&#x27;</span>, ascending=<span class="literal">True</span>)</span><br><span class="line">        collection_report.insert_many(json.loads(new_l.T.to_json()).values())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; items has been update Successed on &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(new_l), time.strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="设置运行时间间隔"><a href="#设置运行时间间隔" class="headerlink" title="设置运行时间间隔"></a>设置运行时间间隔</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_time</span>():</span></span><br><span class="line">    page = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>, <span class="number">0</span>, -<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> page:</span><br><span class="line">        url = <span class="string">&quot;http://www.hibor.com.cn/microns_1_&#123;&#125;.html&quot;</span>.<span class="built_in">format</span>(i)</span><br><span class="line">        detail_urls = spider_detail_urls(url)</span><br><span class="line">        report_data = spider_abstract(detail_urls)</span><br><span class="line">        update_mongodb(report_data)</span><br><span class="line"></span><br><span class="line">schedule.every(<span class="number">4</span>).to(<span class="number">6</span>).days.do(run_time)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        schedule.run_pending()</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/Curtis-Lau/crawl-hibor">本文全部代码详见GitHub</a></p>
]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/post/52060/</url>
    <content><![CDATA[<p>决策树是一种机器学习的方法。决策树的生成算法有ID3, C4.5和C5.0等。决策树是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果。</p>
<p><strong>本文结合实际应用给出手敲的C4.5代码</strong></p>
<span id="more"></span>
<h2 id="ID3简介"><a href="#ID3简介" class="headerlink" title="ID3简介"></a>ID3简介</h2><p><img src="/post/52060/决策树.jpg" alt="决策树"></p>
<p>上面这个图就是一棵典型的决策树。我们在做决策树的时候，会经历两个阶段：<strong>构造</strong>和<strong>剪枝</strong>。</p>
<h3 id="构造"><a href="#构造" class="headerlink" title="构造"></a>构造</h3><p><strong>构造就是生成一棵完整的决策树</strong>。简单来说，<strong>构造的过程就是选择什么属性作为节点的过程</strong>，那么在构造过程中，会存在三种节点：</p>
<ol>
<li>根节点：就是树的最顶端，最开始的那个节点。在上图中，“白不白”就是一个根节点；</li>
<li>内部节点：就是树中间的那些节点，比如说“富不富”、“美不美”；</li>
<li>叶节点：就是树最底部的节点，也就是决策结果。</li>
</ol>
<p>节点之间存在父子关系。比如根节点会有子节点，子节点会有子子节点，但是到了叶节点就停止了，叶节点不存在子节点。那么在构造过程中，你要解决三个重要的问题：</p>
<ol>
<li>选择哪个属性作为根节点；</li>
<li>选择哪些属性作为子节点；</li>
<li>什么时候停止并得到目标状态，即叶节点。</li>
</ol>
<h3 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h3><p>剪枝就是给决策树瘦身，这一步想实现的目标就是，不需要太多的判断，同样可以得到不错的结果。之所以这么做，是为了防止“过拟合”（Overfitting）现象的发生。</p>
<p><strong>过拟合</strong>：指的是模型的训练结果“太好了”，以至于在实际应用的过程中，会存在“死板”的情况，导致分类错误。</p>
<p><strong>欠拟合</strong>：指的是模型的训练结果不理想。</p>
<p><strong>造成过拟合的原因</strong>：</p>
<p>一是因为训练集中样本量较小。如果决策树选择的属性过多，构造出来的决策树一定能够“完美”地把训练集中的样本分类，但是这样就会把训练集中一些数据的特点当成所有数据的特点，但这个特点不一定是全部数据的特点，这就使得这个决策树在真实的数据分类中出现错误，也就是模型的“泛化能力”差。</p>
<p><strong>泛化能力</strong>：指的分类器是通过训练集抽象出来的分类能力，你也可以理解是举一反三的能力。如果我们太依赖于训练集的数据，那么得到的决策树容错率就会比较低，泛化能力差。因为训练集只是全部数据的抽样，并不能体现全部数据的特点。</p>
<p><strong>剪枝的方法</strong>：</p>
<ul>
<li><strong>预剪枝</strong>：在决策树构造时就进行剪枝。方法是，在构造的过程中对节点进行评估，如果对某个节点进行划分，在验证集中不能带来准确性的提升，那么对这个节点进行划分就没有意义，这时就会把当前节点作为叶节点，不对其进行划分。</li>
<li><strong>后剪枝</strong>：在生成决策树之后再进行剪枝。通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉这个节点子树，与保留该节点子树在分类准确性上差别不大，或者剪掉该节点子树，能在验证集中带来准确性的提升，那么就可以把该节点子树进行剪枝。方法是：用这个节点子树的叶子节点来替代该节点，类标记为这个节点子树中最频繁的那个类。</li>
</ul>
<p>在决策过程中有三个重要的问题：将哪个属性作为根节点？选择哪些属性作为后继节点？什么时候停止并得到目标值？</p>
<p>显然将哪个属性（天气、温度、湿度、刮风）作为根节点是个关键问题，在这里我们先介绍两个指标<strong>：纯度</strong>和<strong>信息熵</strong>。</p>
<h3 id="纯度"><a href="#纯度" class="headerlink" title="纯度"></a>纯度</h3><p><strong>你可以把决策树的构造过程理解成为寻找纯净划分的过程</strong>。数学上，我们可以用纯度来表示，纯度换一种方式来解释就是<strong>让目标变量的分歧最小</strong>。</p>
<h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>信息熵的概念本身是信息论中的一个重要概念，因为我们的重点是决策树，所以就不多涉及信息论的知识，我们只需要知道信息熵是什么。</p>
<p><strong>信息熵简单的来说就是表示随机变量不确定度的度量。</strong></p>
<p><strong>熵越大，数据的不确定性就越大。</strong></p>
<p><strong>熵越小，数据的不确定性就越小，也就是越确定。</strong></p>
<p>信息熵计算公式：</p>
<script type="math/tex; mode=display">Entropy(i)=-\displaystyle \sum^n_{i=1}p_i\cdot log(p_i)</script><p>其中 $p_i$ 是指，数据中一共有n类信息，$p_i$就是指第i类数据所占的比例。</p>
<hr>
<p>举个例子：</p>
<p>假设我们的数据中一共有三类。每一类所占比例为$\frac{1}{3}$，那么信息熵就是</p>
<script type="math/tex; mode=display">E=-\frac{1}{3}log(\frac{1}{3})-\frac{1}{3}log(\frac{1}{3})-\frac{1}{3}log(\frac{1}{3})=1.0986</script><p>假设我们数据一共有三类，每类所占比例是0、0、1，那么信息熵就是</p>
<script type="math/tex; mode=display">E=-0log(0)-0log(0)-1log(1)=0</script><p>（注：实际上$log(0)$是不能计算的，定义上不允许，真实场景会做其他处理解决这个问题）</p>
<p>很显然第二组数据比第一组数据信息熵小，也就是不确定性要少，换句话讲就是更为确定。</p>
<hr>
<p>根据这两个例子，应该就能理解<strong>信息熵是随机变量不确定度的度量</strong>了。</p>
<p>如果我们的数据偏向于某一个类别，随机变量的不确定性就降低了，会变的更为确定。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>信息增益指的就是划分可以带来纯度的提高，信息熵的下降。它的计算公式，是<strong>父亲节点的信息熵减去所有子节点的信息熵</strong>。在计算的过程中，我们会计算每个子节点的归一化信息熵，即按照每个子节点在父节点中出现的概率，来计算这些子节点的信息熵。所以信息增益的公式可以表示为：</p>
<script type="math/tex; mode=display">Gain(D,a)=Entropy(D)-\displaystyle \sum^k_{i=1}\frac{|D_i|}{|D|}Entropy(D_i)</script><p>公式中 $D$ 是父亲节点，$D_i$是子节点，$Gain(D,a)$中的$a$ 作为 $D $节点的属性选择。</p>
<p>于是我们通过 ID3 算法得到了一棵决策树。ID3 的算法规则相对简单，可解释性强。同样也存在缺陷，比如我们会发现 <strong>ID3 算法倾向于选择取值比较多的属性</strong>。这样，如果我们把“编号”作为一个属性（一般情况下不会这么做，这里只是举个例子），那么“编号”将会被选为最优属性 。但实际上“编号”是无关属性的，它对“打篮球”的分类并没有太大作用。</p>
<p><strong>所以 ID3 有一个缺陷就是，有些属性可能对分类任务没有太大作用，但是他们仍然可能会被选为最优属性。</strong>这种缺陷不是每次都会发生，只是存在一定的概率。在大部分情况下，ID3 都能生成不错的决策树分类。针对可能发生的缺陷，后人提出了新的算法进行改进。</p>
<h2 id="在-ID3-算法上进行改进的-C4-5-算法"><a href="#在-ID3-算法上进行改进的-C4-5-算法" class="headerlink" title="在 ID3 算法上进行改进的 C4.5 算法"></a>在 ID3 算法上进行改进的 C4.5 算法</h2><h3 id="1-采用信息增益率"><a href="#1-采用信息增益率" class="headerlink" title="1. 采用信息增益率"></a>1. 采用信息增益率</h3><p>因为 ID3 在计算的时候，倾向于选择取值多的属性。为了避免这个问题，C4.5 采用信息增益率的方式来选择属性。<strong>信息增益率 = 信息增益 / 属性熵</strong></p>
<p>当属性有很多值的时候，相当于被划分成了许多份，虽然信息增益变大了，但是对于 C4.5 来说，属性熵也会变大，所以整体的信息增益率并不大。</p>
<h3 id="2-采用悲观剪枝"><a href="#2-采用悲观剪枝" class="headerlink" title="2. 采用悲观剪枝"></a>2. 采用悲观剪枝</h3><p>ID3 构造决策树的时候，容易产生过拟合的情况。在 C4.5中，会在决策树构造之后采用悲观剪枝（PEP），这样可以提升决策树的泛化能力。</p>
<p>悲观剪枝是后剪枝技术中的一种，通过递归估算每个内部节点的分类错误率，比较剪枝前后这个节点的分类错误率来决定是否对其进行剪枝。这种剪枝方法不再需要一个单独的测试数据集。</p>
<h3 id="3-离散化处理连续属性"><a href="#3-离散化处理连续属性" class="headerlink" title="3. 离散化处理连续属性"></a>3. 离散化处理连续属性</h3><p>C4.5 可以处理连续属性的情况，对连续的属性进行离散化的处理。比如打篮球存在的“湿度”属性，不按照“高、中”划分，而是按照湿度值进行计算，那么湿度取什么值都有可能。该怎么选择这个阈值呢，<strong>C4.5 选择具有最高信息增益的划分所对应的阈值</strong>。</p>
<h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><p>首先 ID3 算法的优点是方法简单，缺点是对噪声敏感。训练数据如果有少量错误，可能会产生决策树分类错误。C4.5 在 IID3 的基础上，用信息增益率代替了信息增益，解决了噪声敏感的问题，并且可以对构造树进行剪枝、处理连续数值以及数值缺失等情况，但是由于 C4.5 需要对数据集进行多次扫描，算法效率相对较低。</p>
<p><img src="https://img2018.cnblogs.com/blog/1411882/201904/1411882-20190407131812291-240835919.png" alt></p>
<h2 id="接下来本文运用C4-5算法对HS300股票池股票进行分类"><a href="#接下来本文运用C4-5算法对HS300股票池股票进行分类" class="headerlink" title="接下来本文运用C4.5算法对HS300股票池股票进行分类"></a><strong>接下来本文运用C4.5算法对HS300股票池股票进行分类</strong></h2><hr>
<p>c4.5 决策树 到createTree_c为止 为决策树代码</p>
<p>最终希望达到：</p>
<p>1、组合基本为赢家组合 </p>
<p>2、组内标签大部分相同，少量是别的标签（把最终的熵提出来观察一下）</p>
<p>3、组合间有小部分重复股票——s的设定</p>
<p>4、最终组间画图，用净值或是收益曲线，让组间行情看起来是分开的</p>
<p>本代码的优化：</p>
<p>1、连续变量离散化：函数名带_c的都做了改变</p>
<p>2、设定了s，主要是根据splitDataSet_c函数，让他分得时候错位分</p>
<p>3、最大层高设为了4（退出条件，可改）</p>
<p>4、后面增加了cut_leaf减去输家组合，和getclustercode函数提取item样本，显示每组的股票</p>
<hr>
<p>本文考虑到实际应用，在划分数据集的时考虑的是软划分，即对数据左右划分时用参数使得划分的左右两侧可能存在同样的数据，就是这里的splitDataSet_c函数。</p>
<h3 id="计算熵"><a href="#计算熵" class="headerlink" title="计算熵"></a>计算熵</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    numEntries = <span class="built_in">len</span>(dataSet)   <span class="comment">#计算数据集中实例的总数</span></span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet: <span class="comment">#the the number of unique elements and their occurance</span></span><br><span class="line">        currentLabel = featVec[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys(): labelCounts[currentLabel] = <span class="number">0</span> </span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span>   <span class="comment">#观察每个类别数量</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:   <span class="comment">#使用类别标签发生频率计算类别出现概率</span></span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key])/numEntries</span><br><span class="line">        shannonEnt -= prob*np.math.log(prob,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt   <span class="comment">#熵</span></span><br></pre></td></tr></table></figure>
<h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#选择最优属性时使用（划分数据集）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet_a</span>(<span class="params">dataSet, axis, value, LorR=<span class="string">&#x27;L&#x27;</span></span>):</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">if</span> LorR == <span class="string">&#x27;L&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(featVec[axis]) &lt; value:</span><br><span class="line">                retDataSet.append(featVec)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(featVec[axis]) &gt; value:</span><br><span class="line">                retDataSet.append(featVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line"><span class="comment">#分裂左右子数时，设定一定的错位值s</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet_c</span>(<span class="params">dataSet, axis, value, s, LorR=<span class="string">&#x27;L&#x27;</span></span>):</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">if</span> LorR == <span class="string">&#x27;L&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(featVec[axis]) &lt; value*(<span class="number">1</span>-s):</span><br><span class="line">                retDataSet.append(featVec)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(featVec[axis]) &gt; value*(<span class="number">1</span>+s):</span><br><span class="line">                retDataSet.append(featVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 选择最好的数据集划分方式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit_c</span>(<span class="params">dataSet, labelProperty</span>):</span></span><br><span class="line">    numFeatures = <span class="built_in">len</span>(labelProperty)  <span class="comment"># 特征数</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)  <span class="comment"># 计算根节点的信息熵</span></span><br><span class="line">    infoGainRatio_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeatures):  <span class="comment"># 对每个特征循环</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)  <span class="comment"># 该特征包含的所有值</span></span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">if</span> labelProperty[i] == <span class="number">0</span>:  <span class="comment"># 对离散的特征</span></span><br><span class="line">            <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:  <span class="comment"># 对每个特征值，划分数据集, 计算各子集的信息熵</span></span><br><span class="line">                subDataSet = splitDataSet_a(dataSet, i, value)</span><br><span class="line">                prob = <span class="built_in">len</span>(subDataSet) / <span class="built_in">float</span>(<span class="built_in">len</span>(dataSet))</span><br><span class="line">                newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 对连续的特征</span></span><br><span class="line">            sortedUniqueVals = <span class="built_in">list</span>(uniqueVals)  <span class="comment"># 对特征值排序</span></span><br><span class="line">            sortedUniqueVals.sort()</span><br><span class="line">            <span class="comment">#只取中间段进行划分点选取</span></span><br><span class="line">            sortedUniqueVals = sortedUniqueVals[<span class="built_in">int</span>(<span class="built_in">len</span>(sortedUniqueVals)*<span class="number">0.4</span>):<span class="built_in">int</span>(<span class="built_in">len</span>(sortedUniqueVals)*<span class="number">0.6</span>)]</span><br><span class="line">            maxinfoGainRatio = -np.inf</span><br><span class="line">            bestPartValue = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sortedUniqueVals) - <span class="number">1</span>):  <span class="comment"># 计算划分点</span></span><br><span class="line">                partValue = (<span class="built_in">float</span>(sortedUniqueVals[j]) + <span class="built_in">float</span>(sortedUniqueVals[j+<span class="number">1</span>])) / <span class="number">2</span></span><br><span class="line">                <span class="comment"># 对每个划分点，计算信息熵</span></span><br><span class="line">                dataSetLeft = splitDataSet_a(dataSet, i, partValue,<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">                dataSetRight = splitDataSet_a(dataSet, i, partValue,<span class="string">&#x27;R&#x27;</span>)</span><br><span class="line">                probLeft = <span class="built_in">len</span>(dataSetLeft) / <span class="built_in">float</span>(<span class="built_in">len</span>(dataSet))</span><br><span class="line">                probRight = <span class="built_in">len</span>(dataSetRight) / <span class="built_in">float</span>(<span class="built_in">len</span>(dataSet))</span><br><span class="line">                Entropy = probLeft*calcShannonEnt(dataSetLeft) + probRight*calcShannonEnt(dataSetRight)</span><br><span class="line">                feature_ent = -probLeft*np.math.log(probLeft,<span class="number">2</span>)-probRight*np.math.log(probRight,<span class="number">2</span>)</span><br><span class="line">                infoGainRatio = (baseEntropy - Entropy)/feature_ent</span><br><span class="line">                <span class="keyword">if</span> infoGainRatio &gt; maxinfoGainRatio:</span><br><span class="line">                    maxinfoGainRatio = infoGainRatio</span><br><span class="line">                    bestPartValue = partValue</span><br><span class="line">                infoGainRatio_dict[i] = (bestPartValue,infoGainRatio)</span><br><span class="line"></span><br><span class="line">    sortedbestFeature = <span class="built_in">sorted</span>(infoGainRatio_dict.items(),key=<span class="keyword">lambda</span> x:x[-<span class="number">1</span>][-<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">    bestFeature = sortedbestFeature[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    bestValue = sortedbestFeature[<span class="number">0</span>][<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> bestFeature, bestValue</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#判断数据集的各个属性集是否完全一致</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">judgeEqualLabels</span>(<span class="params">dataSet</span>):</span> </span><br><span class="line">    feature_leng = <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) - <span class="number">1</span>   </span><br><span class="line">    data_leng = <span class="built_in">len</span>(dataSet)</span><br><span class="line">    is_equal = <span class="literal">True</span>    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(feature_leng):</span><br><span class="line">        first_feature = dataSet[<span class="number">0</span>][i]   </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, data_leng):</span><br><span class="line">            <span class="keyword">if</span> first_feature != dataSet[_][i]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>    </span><br><span class="line">    <span class="keyword">return</span> is_equal</span><br></pre></td></tr></table></figure>
<h3 id="投票表决"><a href="#投票表决" class="headerlink" title="投票表决"></a>投票表决</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#投票表决</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span>(<span class="params">classList</span>):</span></span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys(): classCount[vote] = <span class="number">0</span>   <span class="comment">#未出现过，生成一个键值对</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>) <span class="comment">#classCount.iteritems()python3中已经没有这个属性，直接改为items</span></span><br><span class="line">    <span class="comment">#将字典拆为多个元祖[(‘url’, ‘value1’), (‘title’, ‘value2’)]组成的列表</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]   <span class="comment">#返回出现次数最多的分类名称</span></span><br></pre></td></tr></table></figure>
<p>这里包含部分代码，因前期数据处理工作复杂，这里不方便展示，全部代码及数据详见GitHub：</p>
<p><a href="https://github.com/Curtis-Lau/Decision-Tree">本文全部代码详见GitHub</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>遗传算法</title>
    <url>/post/34642/</url>
    <content><![CDATA[<p>遗传算法（Genetic Algorithm, GA）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。</p>
<p>本文结合具体例子讲解。</p>
<span id="more"></span>
<h2 id="什么是遗传算法"><a href="#什么是遗传算法" class="headerlink" title="什么是遗传算法"></a>什么是遗传算法</h2><h3 id="遗传算法的定义"><a href="#遗传算法的定义" class="headerlink" title="遗传算法的定义"></a>遗传算法的定义</h3><p>遗传算法（Genetic Algorithm, GA）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。</p>
<p>其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定；具有内在的隐并行性和更好的全局寻优能力；采用概率化的寻优方法，不需要确定的规则就能自动获取和指导优化的搜索空间，自适应地调整搜索方向。</p>
<p>遗传算法以一种群体中的所有个体为对象，并利用随机化技术指导对一个被编码的参数空间进行高效搜索。其中，选择、交叉和变异构成了遗传算法的遗传操作；参数编码、初始群体的设定、适应度函数的设计、遗传操作设计、控制参数设定五个要素组成了遗传算法的核心内容。</p>
<h3 id="遗传算法的执行过程"><a href="#遗传算法的执行过程" class="headerlink" title="遗传算法的执行过程"></a>遗传算法的执行过程</h3><p>遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，而一个种群则由经过基因（gene）编码的一定数目的个体(individual)组成。每个个体实际上是染色体(chromosome)带有特征的实体。</p>
<p>染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现（即基因型）是某种基因组合，它决定了个体的形状的外部表现，如黑头发的特征是由染色体中控制这一特征的某种基因组合决定的。因此，在一开始需要实现从表现型到基因型的映射即编码工作。由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码。</p>
<p>初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择（selection）个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。</p>
<p>这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解</p>
<p><img src="/post/34642/遗传算法流程图.jpg" alt="遗传算法流程图"></p>
<h2 id="遗传算法相关术语"><a href="#遗传算法相关术语" class="headerlink" title="遗传算法相关术语"></a>遗传算法相关术语</h2><ul>
<li>基因型(genotype)：性状染色体的内部表现；</li>
<li>表现型(phenotype)：染色体决定的性状的外部表现，或者说，根据基因型形成的个体的外部表现；</li>
<li>进化(evolution)：种群逐渐适应生存环境，品质不断得到改良。生物的进化是以种群的形式进行的。</li>
<li>适应度(fitness)：度量某个物种对于生存环境的适应程度。</li>
<li>选择(selection)：以一定的概率从种群中选择若干个个体。一般，选择过程是一种基于适应度的优胜劣汰的过程。</li>
<li>复制(reproduction)：细胞分裂时，遗传物质DNA通过复制而转移到新产生的细胞中，新细胞就继承了旧细胞的基因。</li>
<li>交叉(crossover)：两个染色体的某一相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体。也称基因重组或杂交；</li>
<li>变异(mutation)：复制时可能（很小的概率）产生某些复制差错，变异产生新的染色体，表现出新的性状。</li>
<li>编码(coding)：DNA中遗传信息在一个长链上按一定的模式排列。遗传编码可看作从表现型到基因型的映射。</li>
<li>解码(decoding)：基因型到表现型的映射。</li>
<li>个体（individual）：指染色体带有特征的实体；</li>
<li>种群（population）：个体的集合，该集合内个体数称为种群</li>
</ul>
<h2 id="遗传算法具体步骤"><a href="#遗传算法具体步骤" class="headerlink" title="遗传算法具体步骤"></a>遗传算法具体步骤</h2><h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3><p>需要将问题的解编码成字符串的形式才能使用遗传算法。最简单的一种编码方式是二进制编码，即将问题的解编码成二进制位数组的形式。例如，问题的解是整数，那么可以将其编码成二进制位数组的形式。</p>
<p>基因在一定能够意义上包含了它所代表的问题的解。基因的编码方式有很多，这也取决于要解决的问题本身。常见的编码方式有：</p>
<ol>
<li>二进制编码，基因用0或1表示， 如：基因A：00100011010 (代表一个个体的染色体)；</li>
<li>互换编码（用于解决排序问题，如旅行商问题和调度问题）， 如旅行商问题中，一串基因编码用来表示遍历的城市顺序，如：234517986，表示九个城市中，先经过城市2，再经过城市3，依此类推；</li>
<li>树形编码（用于遗传规划中的演化编程或者表示）。 </li>
</ol>
<p><strong><em>举例：如果要求解函数$F(x)=x \cdot sin(10x) + x \cdot cos(2x)$，其中$x\in[a,b]$，这里就可以使用二进制编码对$x$编码，假设染色体为$g_1g_2…g_{k-1}g_k$，则$x$与染色体的转换方式为：$x= a+(\displaystyle\sum^k_{i=1}g_i \cdot 2^{i-1})\cdot\frac{b-a}{2^k-1}$</em></strong></p>
<p><strong><em>代码如下：</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translateDNA</span>(<span class="params">pop</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pop.dot(<span class="number">2</span>**np.arange(DNA_SIZE)[::-<span class="number">1</span>])/<span class="built_in">float</span>(<span class="number">2</span>**DNA_SIZE-<span class="number">1</span>)*X_BOUND[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h3 id="适应度函数"><a href="#适应度函数" class="headerlink" title="适应度函数"></a>适应度函数</h3><p>适应度函数 ( Fitness Function )：用于评价某个染色体的适应度，用f(x)表示。有时需要区分染色体的适应度函数与问题的目标函数。适应度函数与目标函数是正相关的，可对目标函数作一些变形来得到适应度函数。</p>
<p><strong><em>接上面例子：该题的适应度函数可以每个个体的$F(x_i)$减去群体最小的$F(x)$,但是为了避免下面选择时出现概率为0的情况，所以加上一个很小的值，即：$f(x_i)=F(x_i)-F(x_i)_{min}+0.001$</em></strong>。</p>
<p><strong><em>代码如下：</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_fitness</span>(<span class="params">pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pred + <span class="number">1e-3</span> - np.<span class="built_in">min</span>(pred)</span><br></pre></td></tr></table></figure>
<h3 id="遗传算子"><a href="#遗传算子" class="headerlink" title="遗传算子"></a>遗传算子</h3><p>遗传算子包含3个最基本的操作：选择，交叉，变异。</p>
<h4 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h4><p>选择一些染色体来产生下一代。一种常用的选择策略是 “比例选择”，也就是个体被选中的概率与其适应度函数值成正比。假设群体的个体总数是n，那么那么一个体$X_i$被选中的概率为$\frac {f(X_i)}{\displaystyle \sum^n_{i=1}(f(X_i)}$ 。比例选择实现算法就是所谓的”轮盘赌选择”（ Roulette Wheel Selection）。</p>
<p><strong><em>接上面例子：这里使用轮盘赌选择，具体公式：$p_i=\frac{f(x_i)}{\displaystyle \sum f(x_i)}$</em></strong>。</p>
<p><strong><em>接上面例子：代码如下</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select</span>(<span class="params">pop, fitness</span>):</span></span><br><span class="line">    idx = np.random.choice(np.arange(<span class="built_in">len</span>(pop)), size=<span class="built_in">len</span>(pop), replace=<span class="literal">True</span>,</span><br><span class="line">                           p=fitness/fitness.<span class="built_in">sum</span>())</span><br><span class="line">    <span class="keyword">return</span> pop[idx]</span><br></pre></td></tr></table></figure>
<h4 id="交叉"><a href="#交叉" class="headerlink" title="交叉"></a>交叉</h4><p>所谓交叉运算，是指对两个相互配对的染色体依据交叉概率按某种方式相互交换其部分基因，从而形成两个新的个体。交叉运算在GA中起关键作用，是产生新个体的主要方法。染色体交叉是以一定的概率发生的，这个概率记为$P_c$ 。</p>
<ul>
<li><p>双点交叉法：选择两个交叉点，子代基因在两个交叉点间部分来自一个父代基因，其余部分来自于另外一个父代基因.。</p>
<ul>
<li><p>交叉前：</p>
<p> A染色体：00000|011100000000|10000</p>
<p> B染色体：11100|000001111110|00101</p>
</li>
<li><p>交叉后：</p>
<p> A染色体：00000|000001111110|10000</p>
<p> B染色体：11100|011100000000|00101</p>
</li>
</ul>
</li>
<li><p>基于“ 与/或 ”交叉法 （用于二进制编码）</p>
<ul>
<li>交叉前：</li>
</ul>
<p>​        A染色体：01001011</p>
<p>​        B染色体：11011101</p>
<ul>
<li><p>交叉后：</p>
<p>A染色体：01001001</p>
<p>B染色体：11011111</p>
</li>
</ul>
</li>
</ul>
<p><strong><em>接上面例子：代码如下</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crossover</span>(<span class="params">parent, pop</span>):</span>     <span class="comment"># mating process (genes crossover)</span></span><br><span class="line">    i_ = np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(pop), size=<span class="number">1</span>)      <span class="comment"># 随机挑选另一个individual</span></span><br><span class="line">    cross_points = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=DNA_SIZE).astype(np.<span class="built_in">bool</span>)   <span class="comment"># 选择交叉点（True的位置交叉）</span></span><br><span class="line">    parent[cross_points] = pop[i_, cross_points]     <span class="comment"># 把parent中True对应位置换成individual这个位置的数值</span></span><br><span class="line">    <span class="keyword">return</span> parent</span><br></pre></td></tr></table></figure>
<h4 id="变异"><a href="#变异" class="headerlink" title="变异"></a>变异</h4><p>变异是指依据变异概率将个体编码串中的某些基因值用其它基因值来替换，从而形成一个新的个体。GA中的变异运算是产生新个体的辅助方法，它决定了GA的局部搜索能力，同时保持种群的多样性。交叉运算和变异运算的相互配合，共同完成对搜索空间的全局搜索和局部搜索。</p>
<p><strong>注：变异概率Pm不能太小，这样降低全局搜索能力；也不能太大，$P_m$&gt; 0.5，这时GA退化为随机搜索。</strong></p>
<p>在繁殖过程，新产生的染色体中的基因会以一定的概率出错，称为变异。变异发生的概率记为$P_m$ 。</p>
<ul>
<li><p>基本位变异算子 （用于二进制编码）：是指对个体编码串随机指定的某一位或某几位基因作变异运算。对于基本遗传算法中用二进制编码符号串所表示的个体，若需要进行变异操作的某一基因座上的原有基因值为0，则变异操作将其变为1；反之，若原有基因值为1，则变异操作将其变为0。</p>
<ul>
<li>变异前：000001110000000010000</li>
<li>变异后：000001110000100010000</li>
</ul>
</li>
<li><p>逆转变异算子（用于互换编码）：在个体中随机挑选两个逆转点，再将两个逆转点间的基因交换。 </p>
<ul>
<li>变异前： 1346798205</li>
<li>变异后： 1246798305</li>
</ul>
</li>
</ul>
<p><strong><em>接上面例子：代码如下</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mutate</span>(<span class="params">child</span>):</span></span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> <span class="built_in">range</span>(DNA_SIZE):</span><br><span class="line">        <span class="keyword">if</span> np.random.rand() &lt; MUTATION_RATE:       <span class="comment"># 0.3%的概率基因突变</span></span><br><span class="line">            child[point] = <span class="number">1</span> <span class="keyword">if</span> child[point] == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> child</span><br></pre></td></tr></table></figure>
<h2 id="运行参数"><a href="#运行参数" class="headerlink" title="运行参数"></a>运行参数</h2><p>GA运行时选择的参数应该视解决的具体问题而定，到目前为止，还没有一个适用于GA所有应用领域的关于算法参数的理论。下面是一般情况下使用GA时推荐的参数：</p>
<h3 id="交叉率"><a href="#交叉率" class="headerlink" title="交叉率"></a>交叉率</h3><p>交叉率一般来说应该比较大，推荐使用80％-95％。</p>
<h3 id="变异率"><a href="#变异率" class="headerlink" title="变异率"></a>变异率</h3><p>变异率一般来说应该比较小，一般使用0.5％-1％最好。</p>
<h3 id="种群的规模"><a href="#种群的规模" class="headerlink" title="种群的规模"></a>种群的规模</h3><p>种群规模指的是群体中个体的个数。实验发现，比较大的种群的规模并不能优化遗传算法的结果。种群的大小推荐使用20-30，一些研究表明，种群规模 的大小取决于编码的方法，具体的说就是编码串（Encoded String）的大小。也就是说，如果说采用32位为基因编码的时候种群的规模大小最好为32的话，那么当采用16位为基因编码时种群的规模相应应变为原 来的两倍。</p>
<h3 id="遗传运算的终止进化代数"><a href="#遗传运算的终止进化代数" class="headerlink" title="遗传运算的终止进化代数"></a>遗传运算的终止进化代数</h3><p>个人的想法是，设定一个计数器，如果连续N代出现的最优个体的适应度都一样时，（严格的说应该是，连续N代子代种群的最优个体适应度都&lt;=父代最优个性的适应度）可以终止运算。</p>
<h2 id="遗传算法的优化"><a href="#遗传算法的优化" class="headerlink" title="遗传算法的优化"></a>遗传算法的优化</h2><h3 id="灾变"><a href="#灾变" class="headerlink" title="灾变"></a>灾变</h3><p>遗传算法的局部搜索能力较强，但是很容易陷入局部极值。引用网上的一段原话: 那么如何解决遗传算法容易陷入局部极值的问题呢？让我们来看看大自然提供的方案。</p>
<p>六千五百万年以前，恐龙和灵长类动物并存，恐龙在地球上占绝对统 治地位，如果恐龙没有灭绝灵长类动物是绝没有可能统治地球的。正是恐龙的灭绝才使灵长类动物有了充分进化的余地，事实上地球至少经历了5次物种大灭绝，每 次物种灭绝都给更加高级的生物提供了充分进化的余地。所以要跳出局部极值就必须杀死当前所有的优秀个体，从而让远离当前极值的点有充分的进化余地。这就是灾变的思想。”</p>
<p>灾变就是杀掉最优秀的个体，这样才可能产生更优秀的物种。那何时进行灾变，灾变次数又如何设定？</p>
<p>何时进行灾变，可以采用灾变倒计数的方式。如果n代还没有出现比之前更优秀的个体时，可以发生灾变。灾变次数可以这样来确定，如果若干次灾变后产生的个体的适应度与没灾变前的一样，可停止灾变。</p>
<h3 id="精英主义-Elitist-Strategy-选择："><a href="#精英主义-Elitist-Strategy-选择：" class="headerlink" title="精英主义(Elitist Strategy)选择："></a>精英主义(Elitist Strategy)选择：</h3><p>当利用交叉和变异产生新的一代时，我们有很大的可能把在某个中间步骤中得到的最优解丢失。</p>
<p>精英主义的思想是,在每一次产生新的一代时，首先把当前最优解原封不动的复制到新的一代中。然后按照前面所说的那样做就行。精英主义方法可以大幅提高运算速度，因为它可以防止丢失掉找到的最好的解。</p>
<p>精英主义是基本遗传算法的一种优化。为了防止进化过程中产生的最优解被交叉和变异所破坏，可以将每一代中的最优解原封不动的复制到下一代中。</p>
<h3 id="矛盾"><a href="#矛盾" class="headerlink" title="矛盾"></a>矛盾</h3><p>由上面看来,灾变与精英主义之间似乎存在着矛盾.前者是将产生的最优个体杀掉,而后者是将最优秀个体基因直接保存到下一代.</p>
<p>应该辩证地看待它们之间的矛盾,两者其实是可以共存的.我们在每一代进行交叉运算时,均直接把最优秀的个体复制到下一代;但当连续N代,都没有更优 秀的个体出现时,便可以猜想可能陷入局部最优解了,这样可以采用灾变的手段.可以说,精英主义是伴随的每一代的,但灾变却不需要经常发生,否则算法可能下 降为随机搜索了.</p>
<p>当然,每个算法中不一定要用精英主义和灾变的手段,应该根据具体的问题而定</p>
<h3 id="插入操作："><a href="#插入操作：" class="headerlink" title="插入操作："></a>插入操作：</h3><p>可在3个基本操作的基础上增加一个插入操作。插入操作将染色体中的某个随机的片段移位到另一个随机的位置。</p>
<h2 id="遗传算法的特点"><a href="#遗传算法的特点" class="headerlink" title="遗传算法的特点"></a>遗传算法的特点</h2><h3 id="遗传算法的优点"><a href="#遗传算法的优点" class="headerlink" title="遗传算法的优点:"></a>遗传算法的优点:</h3><ul>
<li>群体搜索，易于并行化处理；</li>
<li>不是盲目穷举，而是启发式搜索；</li>
<li>适应度函数不受连续、可微等条件的约束，适用范围很广。</li>
<li>容易实现。一旦有了一个遗传算法的程序，如果想解决一个新的问题，只需针对新的问题重新进行基因编码就行；如果编码方法也相同，那只需要改变一下适应度函数就可以了。</li>
</ul>
<h3 id="遗传算法的缺点"><a href="#遗传算法的缺点" class="headerlink" title="遗传算法的缺点:"></a>遗传算法的缺点:</h3><ul>
<li>全局搜索能力不强,很容易陷入局部最优解跳不出来；(可结合SA进行改进,因为SA在理率上是100%得到全局最优的,但搜索代价高)</li>
</ul>
<p>将遗传算法用于解决各种实际问题后，人们发现遣传算法也会由于各种原因过早向目标函数的局部最优解收敛，从而很难找到全局最优解。其中有些是由于目标函数的特性造成的，例如函数具有欺骗性，不满足构造模块假说等等；另外一些则是由于算法设计不当。为此，不断有人对遗传算法提出各种各样的改进方案。例如：针对原先的定长二进制编码方案；提出了动态编码、实数编码等改进方案；针对按比例的选择机制，提出了竞争选择、按续挑选等改进方案；针对原先的一点交<em>算子，提出了两点交</em>、多点交<em>、均匀交</em>等算子；针对原先遗传算法各控制参数在进化过程中不变的情况，提出了退化遗传算法、自适应遗传算法等。另外，针对不同问题还出现了分布式遗传算法、并行遗传算法等等。</p>
<p><a href="https://github.com/Curtis-Lau/Genetic-Algorithm">本文全部代码详见GitHub</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>遗传算法</tag>
      </tags>
  </entry>
</search>
